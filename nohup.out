Traceback (most recent call last):
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 328, in <module>
    main()
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 197, in main
    cfg = get_config_from_arg(args)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/utils/run.py", line 59, in get_config_from_arg
    return Config.fromfile(args.config, format_python_code=False)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 456, in fromfile
    lazy_import is None and not Config._is_lazy_import(filename):
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 1657, in _is_lazy_import
    parsed_codes = ast.parse(codes_str)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/ast.py", line 50, in parse
    return compile(source, filename, mode, flags,
  File "<unknown>", line 37
    from .summarizer import dataset_abbrs summary_groups
                                          ^^^^^^^^^^^^^^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 328, in <module>
    main()
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 197, in main
    cfg = get_config_from_arg(args)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/utils/run.py", line 59, in get_config_from_arg
    return Config.fromfile(args.config, format_python_code=False)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 456, in fromfile
    lazy_import is None and not Config._is_lazy_import(filename):
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 1657, in _is_lazy_import
    parsed_codes = ast.parse(codes_str)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/ast.py", line 50, in parse
    return compile(source, filename, mode, flags,
  File "<unknown>", line 37
    from .summarizer import dataset_abbrs summary_groups
                                          ^^^^^^^^^^^^^^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 328, in <module>
    main()
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 197, in main
    cfg = get_config_from_arg(args)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/utils/run.py", line 59, in get_config_from_arg
    return Config.fromfile(args.config, format_python_code=False)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 490, in fromfile
    raise e
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 488, in fromfile
    cfg_dict, imported_names = Config._parse_lazy_import(filename)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 1068, in _parse_lazy_import
    raise ConfigParsingError(
mmengine.config.utils.ConfigParsingError: summarizer.py not found! It means that incorrect module is defined in `with read_base(): = from .summarizer import ...`, please make sure the base config module is valid and is consistent with the prior import logic
Traceback (most recent call last):
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 328, in <module>
    main()
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 197, in main
    cfg = get_config_from_arg(args)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/utils/run.py", line 59, in get_config_from_arg
    return Config.fromfile(args.config, format_python_code=False)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 490, in fromfile
    raise e
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 488, in fromfile
    cfg_dict, imported_names = Config._parse_lazy_import(filename)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 1103, in _parse_lazy_import
    exec(
  File "eval_llama_7b_test.py", line 43, in <module>
    summarizer = dict(dataset_abbrs, summary_groups, )
TypeError: dict expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 328, in <module>
    main()
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 197, in main
    cfg = get_config_from_arg(args)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/utils/run.py", line 59, in get_config_from_arg
    return Config.fromfile(args.config, format_python_code=False)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 490, in fromfile
    raise e
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 488, in fromfile
    cfg_dict, imported_names = Config._parse_lazy_import(filename)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 1103, in _parse_lazy_import
    exec(
  File "eval_llama_7b_test.py", line 43, in <module>
    summarizer = dict(dataset_abbrs, summary_groups, )
TypeError: dict expected at most 1 argument, got 2
11/11 18:38:42 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/11 18:38:42 - OpenCompass - WARNING - Key eval.runner.task.judge_cfg not found in config, ignored.
11/11 18:38:42 - OpenCompass - INFO - Partitioned into 62 tasks.
  0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]launch OpenICLInfer[llama-7b-hf/math_0] on GPU 0,1,2,3,4,5,6,7
11/11 18:39:02 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/math_0] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/math_0.out
  2%|▏         | 1/62 [00:19<19:49, 19.50s/it]                                                2%|▏         | 1/62 [00:19<19:49, 19.50s/it]launch OpenICLInfer[llama-7b-hf/squad2.0_0] on GPU 0,1,2,3,4,5,6,7
11/11 18:39:21 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/squad2.0_0] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/squad2.0_0.out
  3%|▎         | 2/62 [00:39<19:31, 19.52s/it]                                                3%|▎         | 2/62 [00:39<19:31, 19.52s/it]launch OpenICLInfer[llama-7b-hf/squad2.0_1] on GPU 0,1,2,3,4,5,6,7
11/11 18:39:41 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/squad2.0_1] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/squad2.0_1.out
  5%|▍         | 3/62 [00:58<19:06, 19.43s/it]                                                5%|▍         | 3/62 [00:58<19:06, 19.43s/it]launch OpenICLInfer[llama-7b-hf/squad2.0_2] on GPU 0,1,2,3,4,5,6,7
11/11 18:40:00 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/squad2.0_2] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/squad2.0_2.out
  6%|▋         | 4/62 [01:17<18:46, 19.42s/it]                                                6%|▋         | 4/62 [01:17<18:46, 19.42s/it]launch OpenICLInfer[llama-7b-hf/squad2.0_3] on GPU 0,1,2,3,4,5,6,7
11/11 18:40:20 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/squad2.0_3] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/squad2.0_3.out
  8%|▊         | 5/62 [01:37<18:26, 19.42s/it]                                                8%|▊         | 5/62 [01:37<18:26, 19.42s/it]launch OpenICLInfer[llama-7b-hf/squad2.0_4] on GPU 0,1,2,3,4,5,6,7
11/11 18:40:39 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/squad2.0_4] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/squad2.0_4.out
 10%|▉         | 6/62 [01:56<18:10, 19.47s/it]                                               10%|▉         | 6/62 [01:56<18:10, 19.47s/it]launch OpenICLInfer[llama-7b-hf/squad2.0_5] on GPU 0,1,2,3,4,5,6,7
11/11 18:40:59 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/squad2.0_5] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/squad2.0_5.out
 11%|█▏        | 7/62 [02:16<17:51, 19.48s/it]                                               11%|█▏        | 7/62 [02:16<17:51, 19.48s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_0] on GPU 0,1,2,3,4,5,6,7
11/11 18:41:18 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_0] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_0.out
 13%|█▎        | 8/62 [02:35<17:30, 19.45s/it]                                               13%|█▎        | 8/62 [02:35<17:30, 19.45s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_1] on GPU 0,1,2,3,4,5,6,7
11/11 18:41:37 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_1] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_1.out
 15%|█▍        | 9/62 [02:54<17:07, 19.38s/it]                                               15%|█▍        | 9/62 [02:54<17:07, 19.38s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_2] on GPU 0,1,2,3,4,5,6,7
11/11 18:41:56 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_2] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_2.out
 16%|█▌        | 10/62 [03:13<16:41, 19.27s/it]                                                16%|█▌        | 10/62 [03:13<16:41, 19.27s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_3] on GPU 0,1,2,3,4,5,6,7
11/11 18:42:16 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_3] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_3.out
 18%|█▊        | 11/62 [03:33<16:23, 19.28s/it]                                                18%|█▊        | 11/62 [03:33<16:23, 19.28s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_4] on GPU 0,1,2,3,4,5,6,7
11/11 18:42:35 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_4] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_4.out
 19%|█▉        | 12/62 [03:52<16:01, 19.23s/it]                                                19%|█▉        | 12/62 [03:52<16:01, 19.23s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_1shot_0] on GPU 0,1,2,3,4,5,6,7
11/11 18:42:54 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_1shot_0] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_1shot_0.out
 21%|██        | 13/62 [04:11<15:45, 19.29s/it]                                                21%|██        | 13/62 [04:11<15:45, 19.29s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_1shot_1] on GPU 0,1,2,3,4,5,6,7
11/11 18:43:13 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_1shot_1] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_1shot_1.out
 23%|██▎       | 14/62 [04:30<15:24, 19.26s/it]                                                23%|██▎       | 14/62 [04:30<15:24, 19.26s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_1shot_2] on GPU 0,1,2,3,4,5,6,7
11/11 18:43:32 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_1shot_2] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_1shot_2.out
 24%|██▍       | 15/62 [04:49<14:58, 19.11s/it]                                                24%|██▍       | 15/62 [04:49<14:58, 19.11s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_1shot_3] on GPU 0,1,2,3,4,5,6,7
11/11 18:43:59 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_1shot_3] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_1shot_3.out
 26%|██▌       | 16/62 [05:16<16:31, 21.56s/it]                                                26%|██▌       | 16/62 [05:16<16:31, 21.56s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_1shot_4] on GPU 0,1,2,3,4,5,6,7
11/11 19:19:36 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_1shot_4] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_1shot_4.out
 27%|██▋       | 17/62 [40:53<8:13:06, 657.48s/it]                                                   27%|██▋       | 17/62 [40:53<8:13:06, 657.48s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_5shot_0] on GPU 0,1,2,3,4,5,6,7
11/11 19:21:29 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_5shot_0] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_5shot_0.out
 29%|██▉       | 18/62 [42:46<6:02:13, 493.94s/it]                                                   29%|██▉       | 18/62 [42:46<6:02:13, 493.94s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_5shot_1] on GPU 0,1,2,3,4,5,6,7
11/11 19:23:12 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_5shot_1] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_5shot_1.out
 31%|███       | 19/62 [44:30<4:29:56, 376.67s/it]                                                   31%|███       | 19/62 [44:30<4:29:56, 376.67s/it]usage: run.py [-h] [--slurm | --dlc] [--mm-eval]
              [--models MODELS [MODELS ...]]
              [--datasets DATASETS [DATASETS ...]] [--summarizer SUMMARIZER]
              [--debug] [--dry-run] [-m {all,infer,eval,viz}] [-r [REUSE]]
              [-w WORK_DIR] [--config-dir CONFIG_DIR] [-l]
              [--max-partition-size MAX_PARTITION_SIZE]
              [--gen-task-coef GEN_TASK_COEF]
              [--max-num-workers MAX_NUM_WORKERS]
              [--max-workers-per-gpu MAX_WORKERS_PER_GPU] [--retry RETRY]
              [-p PARTITION] [-q QUOTATYPE] [--qos QOS]
              [--aliyun-cfg ALIYUN_CFG] [--hf-path HF_PATH]
              [--peft-path PEFT_PATH] [--tokenizer-path TOKENIZER_PATH]
              [--model-kwargs MODEL_KWARGS [MODEL_KWARGS ...]]
              [--tokenizer-kwargs TOKENIZER_KWARGS [TOKENIZER_KWARGS ...]]
              [--max-out-len MAX_OUT_LEN] [--max-seq-len MAX_SEQ_LEN]
              [--no-batch-padding] [--batch-size BATCH_SIZE]
              [--num-gpus NUM_GPUS] [--pad-token-id PAD_TOKEN_ID]
              [config]
run.py: error: unrecognized arguments: --num_fewshot 5
11/12 01:53:14 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/12 01:53:14 - OpenCompass - WARNING - Key eval.runner.task.judge_cfg not found in config, ignored.
11/12 01:53:14 - OpenCompass - INFO - Partitioned into 2 tasks.
  0%|          | 0/2 [00:00<?, ?it/s]                                       0%|          | 0/2 [00:00<?, ?it/s]launch OpenICLInfer[llama-7b-hf/cmmlu-professional_law,llama-7b-hf/cmmlu-jurisprudence,llama-7b-hf/cmmlu-professional_medicine,llama-7b-hf/cmmlu-chinese_history,llama-7b-hf/cmmlu-college_medicine,llama-7b-hf/cmmlu-elementary_chinese,llama-7b-hf/cmmlu-elementary_information_and_technology,llama-7b-hf/cmmlu-clinical_knowledge,llama-7b-hf/cmmlu-professional_psychology,llama-7b-hf/cmmlu-elementary_mathematics,llama-7b-hf/cmmlu-sociology,llama-7b-hf/cmmlu-legal_and_moral_basis,llama-7b-hf/cmmlu-management,llama-7b-hf/cmmlu-business_ethics,llama-7b-hf/cmmlu-chinese_literature,llama-7b-hf/cmmlu-computer_science,llama-7b-hf/cmmlu-elementary_commonsense,llama-7b-hf/cmmlu-marxist_theory,llama-7b-hf/cmmlu-international_law,llama-7b-hf/cmmlu-traditional_chinese_medicine,llama-7b-hf/cmmlu-marketing,llama-7b-hf/cmmlu-chinese_teacher_qualification,llama-7b-hf/cmmlu-genetics,llama-7b-hf/cmmlu-professional_accounting,llama-7b-hf/cmmlu-public_relations,llama-7b-hf/cmmlu-electrical_engineering,llama-7b-hf/cmmlu-journalism,llama-7b-hf/cmmlu-computer_security,llama-7b-hf/cmmlu-agronomy,llama-7b-hf/cmmlu-high_school_biology,llama-7b-hf/cmmlu-virology,llama-7b-hf/cmmlu-astronomy,llama-7b-hf/cmmlu-sports_science,llama-7b-hf/cmmlu-ancient_chinese,llama-7b-hf/cmmlu-high_school_mathematics,llama-7b-hf/cmmlu-education,llama-7b-hf/cmmlu-world_history,llama-7b-hf/cmmlu-arts,llama-7b-hf/cmmlu-chinese_civil_service_exam] on GPU 0,1,2,3,4,5,6,7
11/12 01:53:37 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/cmmlu-professional_law,llama-7b-hf/cmmlu-jurisprudence,llama-7b-hf/cmmlu-professional_medicine,llama-7b-hf/cmmlu-chinese_history,llama-7b-hf/cmmlu-college_medicine,llama-7b-hf/cmmlu-elementary_chinese,llama-7b-hf/cmmlu-elementary_information_and_technology,llama-7b-hf/cmmlu-clinical_knowledge,llama-7b-hf/cmmlu-professional_psychology,llama-7b-hf/cmmlu-elementary_mathematics,llama-7b-hf/cmmlu-sociology,llama-7b-hf/cmmlu-legal_and_moral_basis,llama-7b-hf/cmmlu-management,llama-7b-hf/cmmlu-business_ethics,llama-7b-hf/cmmlu-chinese_literature,llama-7b-hf/cmmlu-computer_science,llama-7b-hf/cmmlu-elementary_commonsense,llama-7b-hf/cmmlu-marxist_theory,llama-7b-hf/cmmlu-international_law,llama-7b-hf/cmmlu-traditional_chinese_medicine,llama-7b-hf/cmmlu-marketing,llama-7b-hf/cmmlu-chinese_teacher_qualification,llama-7b-hf/cmmlu-genetics,llama-7b-hf/cmmlu-professional_accounting,llama-7b-hf/cmmlu-public_relations,llama-7b-hf/cmmlu-electrical_engineering,llama-7b-hf/cmmlu-journalism,llama-7b-hf/cmmlu-computer_security,llama-7b-hf/cmmlu-agronomy,llama-7b-hf/cmmlu-high_school_biology,llama-7b-hf/cmmlu-virology,llama-7b-hf/cmmlu-astronomy,llama-7b-hf/cmmlu-sports_science,llama-7b-hf/cmmlu-ancient_chinese,llama-7b-hf/cmmlu-high_school_mathematics,llama-7b-hf/cmmlu-education,llama-7b-hf/cmmlu-world_history,llama-7b-hf/cmmlu-arts,llama-7b-hf/cmmlu-chinese_civil_service_exam] fail, see
./outputs/default/20231112_015313/logs/infer/llama-7b-hf/cmmlu-professional_law.out
 50%|█████     | 1/2 [00:23<00:23, 23.14s/it]                                              50%|█████     | 1/2 [00:23<00:23, 23.14s/it]launch OpenICLInfer[llama-7b-hf/cmmlu-world_religions,llama-7b-hf/cmmlu-economics,llama-7b-hf/cmmlu-global_facts,llama-7b-hf/cmmlu-anatomy,llama-7b-hf/cmmlu-conceptual_physics,llama-7b-hf/cmmlu-nutrition,llama-7b-hf/cmmlu-food_science,llama-7b-hf/cmmlu-high_school_politics,llama-7b-hf/cmmlu-construction_project_management,llama-7b-hf/cmmlu-chinese_food_culture,llama-7b-hf/cmmlu-ethnology,llama-7b-hf/cmmlu-security_study,llama-7b-hf/cmmlu-high_school_chemistry,llama-7b-hf/cmmlu-chinese_driving_rule,llama-7b-hf/cmmlu-human_sexuality,llama-7b-hf/cmmlu-logical,llama-7b-hf/cmmlu-machine_learning,llama-7b-hf/cmmlu-high_school_geography,llama-7b-hf/cmmlu-modern_chinese,llama-7b-hf/cmmlu-high_school_physics,llama-7b-hf/cmmlu-college_law,llama-7b-hf/cmmlu-chinese_foreign_policy,llama-7b-hf/cmmlu-college_education,llama-7b-hf/cmmlu-college_actuarial_science,llama-7b-hf/cmmlu-college_engineering_hydrology,llama-7b-hf/cmmlu-college_medical_statistics,llama-7b-hf/cmmlu-college_mathematics,llama-7b-hf/cmmlu-philosophy] on GPU 0,1,2,3,4,5,6,7
11/12 01:54:01 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/cmmlu-world_religions,llama-7b-hf/cmmlu-economics,llama-7b-hf/cmmlu-global_facts,llama-7b-hf/cmmlu-anatomy,llama-7b-hf/cmmlu-conceptual_physics,llama-7b-hf/cmmlu-nutrition,llama-7b-hf/cmmlu-food_science,llama-7b-hf/cmmlu-high_school_politics,llama-7b-hf/cmmlu-construction_project_management,llama-7b-hf/cmmlu-chinese_food_culture,llama-7b-hf/cmmlu-ethnology,llama-7b-hf/cmmlu-security_study,llama-7b-hf/cmmlu-high_school_chemistry,llama-7b-hf/cmmlu-chinese_driving_rule,llama-7b-hf/cmmlu-human_sexuality,llama-7b-hf/cmmlu-logical,llama-7b-hf/cmmlu-machine_learning,llama-7b-hf/cmmlu-high_school_geography,llama-7b-hf/cmmlu-modern_chinese,llama-7b-hf/cmmlu-high_school_physics,llama-7b-hf/cmmlu-college_law,llama-7b-hf/cmmlu-chinese_foreign_policy,llama-7b-hf/cmmlu-college_education,llama-7b-hf/cmmlu-college_actuarial_science,llama-7b-hf/cmmlu-college_engineering_hydrology,llama-7b-hf/cmmlu-college_medical_statistics,llama-7b-hf/cmmlu-college_mathematics,llama-7b-hf/cmmlu-philosophy] fail, see
./outputs/default/20231112_015313/logs/infer/llama-7b-hf/cmmlu-world_religions.out
100%|██████████| 2/2 [00:46<00:00, 23.20s/it]100%|██████████| 2/2 [00:46<00:00, 23.19s/it]
11/12 01:54:01 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/cmmlu-professional_law,llama-7b-hf/cmmlu-jurisprudence,llama-7b-hf/cmmlu-professional_medicine,llama-7b-hf/cmmlu-chinese_history,llama-7b-hf/cmmlu-college_medicine,llama-7b-hf/cmmlu-elementary_chinese,llama-7b-hf/cmmlu-elementary_information_and_technology,llama-7b-hf/cmmlu-clinical_knowledge,llama-7b-hf/cmmlu-professional_psychology,llama-7b-hf/cmmlu-elementary_mathematics,llama-7b-hf/cmmlu-sociology,llama-7b-hf/cmmlu-legal_and_moral_basis,llama-7b-hf/cmmlu-management,llama-7b-hf/cmmlu-business_ethics,llama-7b-hf/cmmlu-chinese_literature,llama-7b-hf/cmmlu-computer_science,llama-7b-hf/cmmlu-elementary_commonsense,llama-7b-hf/cmmlu-marxist_theory,llama-7b-hf/cmmlu-international_law,llama-7b-hf/cmmlu-traditional_chinese_medicine,llama-7b-hf/cmmlu-marketing,llama-7b-hf/cmmlu-chinese_teacher_qualification,llama-7b-hf/cmmlu-genetics,llama-7b-hf/cmmlu-professional_accounting,llama-7b-hf/cmmlu-public_relations,llama-7b-hf/cmmlu-electrical_engineering,llama-7b-hf/cmmlu-journalism,llama-7b-hf/cmmlu-computer_security,llama-7b-hf/cmmlu-agronomy,llama-7b-hf/cmmlu-high_school_biology,llama-7b-hf/cmmlu-virology,llama-7b-hf/cmmlu-astronomy,llama-7b-hf/cmmlu-sports_science,llama-7b-hf/cmmlu-ancient_chinese,llama-7b-hf/cmmlu-high_school_mathematics,llama-7b-hf/cmmlu-education,llama-7b-hf/cmmlu-world_history,llama-7b-hf/cmmlu-arts,llama-7b-hf/cmmlu-chinese_civil_service_exam] failed with code 1
11/12 01:54:01 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/cmmlu-world_religions,llama-7b-hf/cmmlu-economics,llama-7b-hf/cmmlu-global_facts,llama-7b-hf/cmmlu-anatomy,llama-7b-hf/cmmlu-conceptual_physics,llama-7b-hf/cmmlu-nutrition,llama-7b-hf/cmmlu-food_science,llama-7b-hf/cmmlu-high_school_politics,llama-7b-hf/cmmlu-construction_project_management,llama-7b-hf/cmmlu-chinese_food_culture,llama-7b-hf/cmmlu-ethnology,llama-7b-hf/cmmlu-security_study,llama-7b-hf/cmmlu-high_school_chemistry,llama-7b-hf/cmmlu-chinese_driving_rule,llama-7b-hf/cmmlu-human_sexuality,llama-7b-hf/cmmlu-logical,llama-7b-hf/cmmlu-machine_learning,llama-7b-hf/cmmlu-high_school_geography,llama-7b-hf/cmmlu-modern_chinese,llama-7b-hf/cmmlu-high_school_physics,llama-7b-hf/cmmlu-college_law,llama-7b-hf/cmmlu-chinese_foreign_policy,llama-7b-hf/cmmlu-college_education,llama-7b-hf/cmmlu-college_actuarial_science,llama-7b-hf/cmmlu-college_engineering_hydrology,llama-7b-hf/cmmlu-college_medical_statistics,llama-7b-hf/cmmlu-college_mathematics,llama-7b-hf/cmmlu-philosophy] failed with code 1
11/12 01:54:01 - OpenCompass - INFO - Partitioned into 67 tasks.
  0%|          | 0/67 [00:00<?, ?it/s]                                        0%|          | 0/67 [00:00<?, ?it/s]                                        0%|          | 0/67 [00:00<?, ?it/s]                                        0%|          | 0/67 [00:00<?, ?it/s]                                        0%|          | 0/67 [00:00<?, ?it/s]                                        0%|          | 0/67 [00:00<?, ?it/s]                                        0%|          | 0/67 [00:00<?, ?it/s]                                        0%|          | 0/67 [00:00<?, ?it/s]                                        0%|          | 0/67 [00:00<?, ?it/s]                                        0%|          | 0/67 [00:00<?, ?it/s]                                        0%|          | 0/67 [00:01<?, ?it/s]                                        0%|          | 0/67 [00:01<?, ?it/s]                                        0%|          | 0/67 [00:01<?, ?it/s]                                        0%|          | 0/67 [00:02<?, ?it/s]                                        0%|          | 0/67 [00:02<?, ?it/s]                                        0%|          | 0/67 [00:02<?, ?it/s]                                        0%|          | 0/67 [00:03<?, ?it/s]                                        0%|          | 0/67 [00:04<?, ?it/s]                                        0%|          | 0/67 [00:04<?, ?it/s]                                        0%|          | 0/67 [00:05<?, ?it/s]                                        0%|          | 0/67 [00:05<?, ?it/s]                                        0%|          | 0/67 [00:06<?, ?it/s]                                        0%|          | 0/67 [00:06<?, ?it/s]                                        0%|          | 0/67 [00:07<?, ?it/s]                                        0%|          | 0/67 [00:08<?, ?it/s]                                        0%|          | 0/67 [00:09<?, ?it/s]                                        0%|          | 0/67 [00:11<?, ?it/s]                                        0%|          | 0/67 [00:11<?, ?it/s]                                        0%|          | 0/67 [00:14<?, ?it/s]                                        0%|          | 0/67 [00:15<?, ?it/s]                                        0%|          | 0/67 [00:15<?, ?it/s]                                        0%|          | 0/67 [00:16<?, ?it/s]                                        0%|          | 0/67 [00:17<?, ?it/s]  1%|▏         | 1/67 [00:45<49:43, 45.21s/it]  3%|▎         | 2/67 [00:45<30:50, 28.46s/it]                                                3%|▎         | 2/67 [00:46<30:50, 28.46s/it]                                                3%|▎         | 2/67 [00:47<30:50, 28.46s/it]  4%|▍         | 3/67 [00:47<20:47, 19.49s/it]                                                4%|▍         | 3/67 [00:47<20:47, 19.49s/it]  6%|▌         | 4/67 [00:49<14:17, 13.61s/it]                                                6%|▌         | 4/67 [00:49<14:17, 13.61s/it]  7%|▋         | 5/67 [00:50<09:47,  9.47s/it]                                                7%|▋         | 5/67 [00:50<09:47,  9.47s/it]  9%|▉         | 6/67 [00:51<07:06,  7.00s/it] 12%|█▏        | 8/67 [00:52<03:05,  3.14s/it]                                               13%|█▎        | 9/67 [00:52<02:23,  2.47s/it] 13%|█▎        | 9/67 [00:52<02:23,  2.47s/it]                                               16%|█▋        | 11/67 [00:54<00:54,  1.04it/s] 16%|█▋        | 11/67 [00:54<00:54,  1.04it/s] 18%|█▊        | 12/67 [00:55<01:08,  1.24s/it] 18%|█▊        | 12/67 [00:55<01:08,  1.24s/it]                                                18%|█▊        | 12/67 [00:56<01:08,  1.24s/it]                                                18%|█▊        | 12/67 [00:56<01:08,  1.24s/it] 18%|█▊        | 12/67 [00:56<01:08,  1.24s/it]                                                18%|█▊        | 12/67 [00:57<01:08,  1.24s/it]                                                19%|█▉        | 13/67 [00:57<01:24,  1.57s/it]                                                19%|█▉        | 13/67 [00:58<01:24,  1.57s/it] 19%|█▉        | 13/67 [00:58<01:24,  1.57s/it]                                                19%|█▉        | 13/67 [00:59<01:24,  1.57s/it] 21%|██        | 14/67 [00:59<01:26,  1.63s/it]                                                21%|██        | 14/67 [00:59<01:26,  1.63s/it] 22%|██▏       | 15/67 [01:01<01:30,  1.74s/it] 24%|██▍       | 16/67 [01:02<01:16,  1.50s/it]                                                27%|██▋       | 18/67 [01:02<00:41,  1.18it/s] 28%|██▊       | 19/67 [01:03<00:45,  1.05it/s] 30%|██▉       | 20/67 [01:03<00:52,  1.12s/it]                                                31%|███▏      | 21/67 [01:04<01:01,  1.33s/it] 31%|███▏      | 21/67 [01:04<01:01,  1.33s/it]                                                31%|███▏      | 21/67 [01:05<01:01,  1.33s/it] 31%|███▏      | 21/67 [01:05<01:01,  1.33s/it]                                                31%|███▏      | 21/67 [01:07<01:01,  1.33s/it] 31%|███▏      | 21/67 [01:07<01:01,  1.33s/it]                                                33%|███▎      | 22/67 [01:08<01:33,  2.07s/it]                                                33%|███▎      | 22/67 [01:09<01:33,  2.07s/it] 33%|███▎      | 22/67 [01:09<01:33,  2.07s/it]                                                36%|███▌      | 24/67 [01:10<01:58,  2.75s/it] 37%|███▋      | 25/67 [01:10<01:29,  2.12s/it]                                                37%|███▋      | 25/67 [01:11<01:29,  2.12s/it] 37%|███▋      | 25/67 [01:11<01:29,  2.12s/it] 37%|███▋      | 25/67 [01:11<01:29,  2.12s/it]                                                37%|███▋      | 25/67 [01:12<01:29,  2.12s/it]                                                37%|███▋      | 25/67 [01:14<01:29,  2.12s/it]                                                37%|███▋      | 25/67 [01:15<01:29,  2.12s/it] 39%|███▉      | 26/67 [01:15<01:57,  2.86s/it]                                                39%|███▉      | 26/67 [01:16<01:57,  2.86s/it] 40%|████      | 27/67 [01:20<02:13,  3.35s/it]                                                40%|████      | 27/67 [01:20<02:13,  3.35s/it] 42%|████▏     | 28/67 [01:20<01:39,  2.56s/it]                                                43%|████▎     | 29/67 [01:21<01:12,  1.91s/it] 45%|████▍     | 30/67 [01:21<00:46,  1.25s/it] 45%|████▍     | 30/67 [01:22<00:46,  1.25s/it]                                                45%|████▍     | 30/67 [01:23<00:46,  1.25s/it]                                                45%|████▍     | 30/67 [01:24<00:46,  1.25s/it] 46%|████▋     | 31/67 [01:27<01:21,  2.27s/it]                                                48%|████▊     | 32/67 [01:27<01:02,  1.79s/it] 48%|████▊     | 32/67 [01:28<01:02,  1.79s/it]                                                48%|████▊     | 32/67 [01:28<01:02,  1.79s/it] 49%|████▉     | 33/67 [01:50<04:15,  7.51s/it]                                                49%|████▉     | 33/67 [01:51<04:15,  7.51s/it] 51%|█████     | 34/67 [01:56<03:53,  7.06s/it]                                                52%|█████▏    | 35/67 [01:57<02:51,  5.37s/it] 52%|█████▏    | 35/67 [01:58<02:51,  5.37s/it]                                                54%|█████▎    | 36/67 [01:59<02:09,  4.18s/it] 54%|█████▎    | 36/67 [01:59<02:09,  4.18s/it] 55%|█████▌    | 37/67 [02:03<02:05,  4.18s/it] 57%|█████▋    | 38/67 [02:03<01:28,  3.06s/it] 58%|█████▊    | 39/67 [02:04<01:08,  2.44s/it] 60%|█████▉    | 40/67 [02:08<01:15,  2.78s/it] 61%|██████    | 41/67 [02:09<01:00,  2.34s/it] 63%|██████▎   | 42/67 [02:10<00:49,  1.98s/it] 64%|██████▍   | 43/67 [02:11<00:39,  1.63s/it] 66%|██████▌   | 44/67 [02:16<01:00,  2.62s/it] 67%|██████▋   | 45/67 [02:16<00:42,  1.93s/it] 69%|██████▊   | 46/67 [02:16<00:29,  1.40s/it] 70%|███████   | 47/67 [02:17<00:25,  1.28s/it] 72%|███████▏  | 48/67 [02:18<00:20,  1.09s/it] 73%|███████▎  | 49/67 [02:20<00:23,  1.32s/it] 75%|███████▍  | 50/67 [02:21<00:19,  1.17s/it] 76%|███████▌  | 51/67 [02:21<00:13,  1.15it/s] 78%|███████▊  | 52/67 [02:21<00:10,  1.42it/s] 79%|███████▉  | 53/67 [02:24<00:18,  1.35s/it] 81%|████████  | 54/67 [02:24<00:13,  1.06s/it] 84%|████████▎ | 56/67 [02:25<00:07,  1.55it/s] 85%|████████▌ | 57/67 [02:25<00:05,  1.95it/s] 87%|████████▋ | 58/67 [02:25<00:03,  2.41it/s] 88%|████████▊ | 59/67 [02:25<00:02,  2.90it/s] 90%|████████▉ | 60/67 [02:25<00:02,  2.86it/s] 91%|█████████ | 61/67 [02:26<00:02,  2.66it/s] 94%|█████████▍| 63/67 [02:26<00:01,  3.31it/s] 97%|█████████▋| 65/67 [02:28<00:00,  2.11it/s] 99%|█████████▊| 66/67 [02:28<00:00,  2.05it/s]100%|██████████| 67/67 [02:28<00:00,  2.22s/it]
launch OpenICLEval[llama-7b-hf/cmmlu-agronomy] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-anatomy] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-ancient_chinese] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-arts] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-astronomy] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-business_ethics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_civil_service_exam] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_driving_rule] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_food_culture] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_foreign_policy] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_history] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_literature] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_teacher_qualification] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-clinical_knowledge] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_actuarial_science] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_education] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_engineering_hydrology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_law] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_medical_statistics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-computer_security] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-conceptual_physics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-construction_project_management] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-economics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-education] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-electrical_engineering] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-elementary_chinese] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-elementary_commonsense] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-elementary_information_and_technology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-elementary_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-ethnology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-food_science] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-genetics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-global_facts] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-high_school_biology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-high_school_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-high_school_geography] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-high_school_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-high_school_physics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-high_school_politics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-human_sexuality] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-international_law] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-journalism] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-jurisprudence] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-legal_and_moral_basis] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-logical] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-machine_learning] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-management] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-marketing] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-marxist_theory] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-modern_chinese] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-nutrition] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-philosophy] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-professional_accounting] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-professional_law] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-professional_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-professional_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-public_relations] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-security_study] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-sociology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-sports_science] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-traditional_chinese_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-virology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-world_history] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-world_religions] on CPU 
dataset                       version    metric    mode    llama-7b-hf
----------------------------  ---------  --------  ------  -------------
------- MMLU details -------  -          -         -       -
mmlu-humanities               -          -         -       -
mmlu-stem                     -          -         -       -
mmlu-social-science           -          -         -       -
mmlu-other                    -          -         -       -
mmlu                          -          -         -       -
---- Standard Benchmarks ---  -          -         -       -
BoolQ                         -          -         -       -
piqa                          -          -         -       -
siqa                          -          -         -       -
hellaswag                     -          -         -       -
winogrande                    -          -         -       -
ARC-e                         -          -         -       -
ARC-c                         -          -         -       -
openbookqa_fact               -          -         -       -
commonsense_qa                -          -         -       -
mmlu                          -          -         -       -
------ Code Generation -----  -          -         -       -
openai_humaneval              -          -         -       -
mbpp                          -          -         -       -
------ World Knowledge -----  -          -         -       -
triviaqa                      -          -         -       -
--- Reading Comprehension --  -          -         -       -
squad2.0                      -          -         -       -
---------- Exams -----------  -          -         -       -
math                          -          -         -       -
gsm8k                         -          -         -       -
TheoremQA                     -          -         -       -
--------- Chinese ----------  -          -         -       -
ceval                         -          -         -       -
ceval-stem                    -          -         -       -
ceval-social-science          -          -         -       -
ceval-humanities              -          -         -       -
ceval-other                   -          -         -       -
ceval-hard                    -          -         -       -
ceval-test-stem               -          -         -       -
ceval-test-social-science     -          -         -       -
ceval-test-humanities         -          -         -       -
ceval-test-other              -          -         -       -
ceval-test-hard               -          -         -       -
ceval-test                    -          -         -       -
cmmlu                         -          -         -       -
cmmlu-humanities              -          -         -       -
cmmlu-stem                    -          -         -       -
cmmlu-social-science          -          -         -       -
cmmlu-other                   -          -         -       -
cmmlu-china-specific          -          -         -       -
11/12 01:56:29 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_015313/summary/summary_20231112_015313.txt
11/12 01:56:29 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_015313/summary/summary_20231112_015313.csv
11/12 01:57:39 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/12 01:57:39 - OpenCompass - WARNING - Key eval.runner.task.judge_cfg not found in config, ignored.
11/12 01:57:39 - OpenCompass - INFO - Partitioned into 4 tasks.
  0%|          | 0/4 [00:00<?, ?it/s]                                       0%|          | 0/4 [00:00<?, ?it/s]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] on GPU 0,1,2,3,4,5,6,7
11/12 01:58:00 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] fail, see
./outputs/default/20231112_015739/logs/infer/llama-7b-hf/lukaemon_mmlu_professional_law_0.out
 25%|██▌       | 1/4 [00:20<01:02, 20.82s/it]                                              25%|██▌       | 1/4 [00:21<01:02, 20.82s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] on GPU 0,1,2,3,4,5,6,7
11/12 01:58:21 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] fail, see
./outputs/default/20231112_015739/logs/infer/llama-7b-hf/lukaemon_mmlu_professional_law_1.out
 50%|█████     | 2/4 [00:41<00:41, 20.82s/it]                                              50%|█████     | 2/4 [00:42<00:41, 20.82s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] on GPU 0,1,2,3,4,5,6,7
11/12 01:58:43 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] fail, see
./outputs/default/20231112_015739/logs/infer/llama-7b-hf/lukaemon_mmlu_moral_scenarios.out
 75%|███████▌  | 3/4 [01:03<00:21, 21.52s/it]                                              75%|███████▌  | 3/4 [01:04<00:21, 21.52s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] on GPU 0,1,2,3,4,5,6,7
11/12 01:59:06 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] fail, see
./outputs/default/20231112_015739/logs/infer/llama-7b-hf/lukaemon_mmlu_high_school_physics.out
100%|██████████| 4/4 [01:26<00:00, 21.80s/it]100%|██████████| 4/4 [01:26<00:00, 21.56s/it]
11/12 01:59:06 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] failed with code 1
11/12 01:59:06 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] failed with code 1
11/12 01:59:06 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] failed with code 1
11/12 01:59:06 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] failed with code 1
11/12 01:59:06 - OpenCompass - INFO - Partitioned into 57 tasks.
  0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:01<?, ?it/s]                                        0%|          | 0/57 [00:01<?, ?it/s]                                        0%|          | 0/57 [00:02<?, ?it/s]                                        0%|          | 0/57 [00:03<?, ?it/s]                                        0%|          | 0/57 [00:03<?, ?it/s]                                        0%|          | 0/57 [00:03<?, ?it/s]                                        0%|          | 0/57 [00:04<?, ?it/s]                                        0%|          | 0/57 [00:05<?, ?it/s]                                        0%|          | 0/57 [00:07<?, ?it/s]                                        0%|          | 0/57 [00:09<?, ?it/s]                                        0%|          | 0/57 [00:09<?, ?it/s]                                        0%|          | 0/57 [00:11<?, ?it/s]                                        0%|          | 0/57 [00:12<?, ?it/s]                                        0%|          | 0/57 [00:13<?, ?it/s]                                        0%|          | 0/57 [00:13<?, ?it/s]                                        0%|          | 0/57 [00:15<?, ?it/s]                                        0%|          | 0/57 [00:16<?, ?it/s]                                        0%|          | 0/57 [00:17<?, ?it/s]                                        2%|▏         | 1/57 [00:18<17:07, 18.34s/it]                                                2%|▏         | 1/57 [00:19<17:07, 18.34s/it]                                                5%|▌         | 3/57 [00:20<07:56,  8.82s/it]                                                5%|▌         | 3/57 [00:20<07:56,  8.82s/it]                                                5%|▌         | 3/57 [00:21<07:56,  8.82s/it]                                                5%|▌         | 3/57 [00:21<07:56,  8.82s/it]  7%|▋         | 4/57 [00:22<06:08,  6.96s/it]  7%|▋         | 4/57 [00:22<06:08,  6.96s/it]  9%|▉         | 5/57 [00:22<05:36,  6.48s/it]  9%|▉         | 5/57 [00:22<05:36,  6.48s/it]                                                9%|▉         | 5/57 [00:22<05:36,  6.48s/it]  9%|▉         | 5/57 [00:23<05:36,  6.48s/it]                                                9%|▉         | 5/57 [00:23<05:36,  6.48s/it]                                               12%|█▏        | 7/57 [00:23<03:11,  3.84s/it]                                               12%|█▏        | 7/57 [00:25<03:11,  3.84s/it]                                               18%|█▊        | 10/57 [00:25<00:59,  1.26s/it] 18%|█▊        | 10/57 [00:26<00:59,  1.26s/it] 18%|█▊        | 10/57 [00:26<00:59,  1.26s/it] 19%|█▉        | 11/57 [00:27<01:13,  1.60s/it] 21%|██        | 12/57 [00:28<01:21,  1.80s/it] 23%|██▎       | 13/57 [00:28<01:29,  2.02s/it]                                                25%|██▍       | 14/57 [00:28<01:37,  2.26s/it]                                                25%|██▍       | 14/57 [00:29<01:37,  2.26s/it] 25%|██▍       | 14/57 [00:29<01:37,  2.26s/it]                                                25%|██▍       | 14/57 [00:30<01:37,  2.26s/it] 25%|██▍       | 14/57 [00:31<01:37,  2.26s/it]                                                26%|██▋       | 15/57 [00:32<01:50,  2.63s/it] 26%|██▋       | 15/57 [00:32<01:50,  2.63s/it]                                                26%|██▋       | 15/57 [00:33<01:50,  2.63s/it] 26%|██▋       | 15/57 [00:33<01:50,  2.63s/it]                                                26%|██▋       | 15/57 [00:34<01:50,  2.63s/it]                                                26%|██▋       | 15/57 [00:35<01:50,  2.63s/it] 26%|██▋       | 15/57 [00:36<01:50,  2.63s/it]                                                26%|██▋       | 15/57 [00:37<01:50,  2.63s/it]                                                26%|██▋       | 15/57 [00:38<01:50,  2.63s/it]                                                28%|██▊       | 16/57 [00:39<02:27,  3.59s/it] 28%|██▊       | 16/57 [00:39<02:27,  3.59s/it]                                                28%|██▊       | 16/57 [00:39<02:27,  3.59s/it] 30%|██▉       | 17/57 [00:44<02:43,  4.08s/it]                                                30%|██▉       | 17/57 [00:45<02:43,  4.08s/it] 32%|███▏      | 18/57 [00:48<02:40,  4.12s/it]                                                32%|███▏      | 18/57 [00:49<02:40,  4.12s/it] 33%|███▎      | 19/57 [00:50<02:02,  3.24s/it]                                                33%|███▎      | 19/57 [00:51<02:02,  3.24s/it] 35%|███▌      | 20/57 [00:54<02:12,  3.59s/it] 39%|███▊      | 22/57 [00:54<01:20,  2.31s/it] 40%|████      | 23/57 [00:54<01:06,  1.95s/it]                                                40%|████      | 23/57 [00:56<01:06,  1.95s/it]                                                46%|████▌     | 26/57 [00:56<00:40,  1.29s/it] 46%|████▌     | 26/57 [00:57<00:40,  1.29s/it]                                                46%|████▌     | 26/57 [00:58<00:40,  1.29s/it] 46%|████▌     | 26/57 [00:58<00:40,  1.29s/it] 46%|████▌     | 26/57 [00:58<00:40,  1.29s/it] 46%|████▌     | 26/57 [00:59<00:40,  1.29s/it]                                                46%|████▌     | 26/57 [00:59<00:40,  1.29s/it]                                                46%|████▌     | 26/57 [00:59<00:40,  1.29s/it]                                                46%|████▌     | 26/57 [01:00<00:40,  1.29s/it] 47%|████▋     | 27/57 [01:02<01:02,  2.09s/it] 49%|████▉     | 28/57 [01:04<00:57,  1.97s/it] 51%|█████     | 29/57 [01:04<00:42,  1.53s/it] 53%|█████▎    | 30/57 [01:05<00:39,  1.47s/it] 54%|█████▍    | 31/57 [01:05<00:32,  1.26s/it] 56%|█████▌    | 32/57 [01:07<00:35,  1.42s/it] 58%|█████▊    | 33/57 [01:08<00:32,  1.34s/it] 60%|█████▉    | 34/57 [01:09<00:27,  1.18s/it] 61%|██████▏   | 35/57 [01:10<00:22,  1.01s/it] 63%|██████▎   | 36/57 [01:10<00:16,  1.24it/s] 65%|██████▍   | 37/57 [01:11<00:14,  1.35it/s] 67%|██████▋   | 38/57 [01:11<00:14,  1.32it/s] 68%|██████▊   | 39/57 [01:12<00:10,  1.65it/s] 70%|███████   | 40/57 [01:14<00:18,  1.06s/it] 72%|███████▏  | 41/57 [01:16<00:22,  1.38s/it] 74%|███████▎  | 42/57 [01:16<00:15,  1.05s/it] 75%|███████▌  | 43/57 [01:18<00:15,  1.14s/it] 77%|███████▋  | 44/57 [01:18<00:10,  1.18it/s] 79%|███████▉  | 45/57 [01:18<00:08,  1.45it/s] 81%|████████  | 46/57 [01:19<00:07,  1.57it/s] 82%|████████▏ | 47/57 [01:20<00:06,  1.44it/s] 84%|████████▍ | 48/57 [01:22<00:10,  1.18s/it] 86%|████████▌ | 49/57 [01:22<00:07,  1.08it/s] 89%|████████▉ | 51/57 [01:24<00:04,  1.21it/s] 91%|█████████ | 52/57 [01:25<00:04,  1.05it/s] 93%|█████████▎| 53/57 [01:25<00:03,  1.23it/s] 96%|█████████▋| 55/57 [01:26<00:00,  2.01it/s]100%|██████████| 57/57 [01:26<00:00,  3.02it/s]100%|██████████| 57/57 [01:26<00:00,  1.51s/it]
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_biology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_physics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_electrical_engineering] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_astronomy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_anatomy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_abstract_algebra] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_machine_learning] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_clinical_knowledge] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_global_facts] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_management] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_nutrition] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_marketing] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_accounting] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_geography] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_international_law] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_moral_scenarios] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_computer_security] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_microeconomics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_law] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_medical_genetics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_jurisprudence] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_world_religions] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_philosophy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_virology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_public_relations] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_human_sexuality] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_elementary_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_physics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_european_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_business_ethics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_moral_disputes] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_statistics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_miscellaneous] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_formal_logic] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_prehistory] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_security_studies] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_biology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_logical_fallacies] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_world_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_us_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_sociology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_econometrics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_human_aging] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_us_foreign_policy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_conceptual_physics] on CPU 
dataset                       version    metric    mode    llama-7b-hf
----------------------------  ---------  --------  ------  -------------
------- MMLU details -------  -          -         -       -
mmlu-humanities               -          -         -       -
mmlu-stem                     -          -         -       -
mmlu-social-science           -          -         -       -
mmlu-other                    -          -         -       -
mmlu                          -          -         -       -
---- Standard Benchmarks ---  -          -         -       -
BoolQ                         -          -         -       -
piqa                          -          -         -       -
siqa                          -          -         -       -
hellaswag                     -          -         -       -
winogrande                    -          -         -       -
ARC-e                         -          -         -       -
ARC-c                         -          -         -       -
openbookqa_fact               -          -         -       -
commonsense_qa                -          -         -       -
mmlu                          -          -         -       -
------ Code Generation -----  -          -         -       -
openai_humaneval              -          -         -       -
mbpp                          -          -         -       -
------ World Knowledge -----  -          -         -       -
triviaqa                      -          -         -       -
--- Reading Comprehension --  -          -         -       -
squad2.0                      -          -         -       -
---------- Exams -----------  -          -         -       -
math                          -          -         -       -
gsm8k                         -          -         -       -
TheoremQA                     -          -         -       -
--------- Chinese ----------  -          -         -       -
ceval                         -          -         -       -
ceval-stem                    -          -         -       -
ceval-social-science          -          -         -       -
ceval-humanities              -          -         -       -
ceval-other                   -          -         -       -
ceval-hard                    -          -         -       -
ceval-test-stem               -          -         -       -
ceval-test-social-science     -          -         -       -
ceval-test-humanities         -          -         -       -
ceval-test-other              -          -         -       -
ceval-test-hard               -          -         -       -
ceval-test                    -          -         -       -
cmmlu                         -          -         -       -
cmmlu-humanities              -          -         -       -
cmmlu-stem                    -          -         -       -
cmmlu-social-science          -          -         -       -
cmmlu-other                   -          -         -       -
cmmlu-china-specific          -          -         -       -
11/12 02:00:32 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_015739/summary/summary_20231112_015739.txt
11/12 02:00:32 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_015739/summary/summary_20231112_015739.csv
11/12 02:01:33 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/12 02:01:33 - OpenCompass - WARNING - Key eval.runner.task.judge_cfg not found in config, ignored.
11/12 02:01:33 - OpenCompass - INFO - Partitioned into 4 tasks.
  0%|          | 0/4 [00:00<?, ?it/s]                                       0%|          | 0/4 [00:00<?, ?it/s]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] on GPU 0,1,2,3,4,5,6,7
11/12 02:01:55 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] fail, see
./outputs/default/20231112_020133/logs/infer/llama-7b-hf/lukaemon_mmlu_professional_law_0.out
 25%|██▌       | 1/4 [00:21<01:05, 21.82s/it]                                              25%|██▌       | 1/4 [00:22<01:05, 21.82s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] on GPU 0,1,2,3,4,5,6,7
11/12 02:02:17 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] fail, see
./outputs/default/20231112_020133/logs/infer/llama-7b-hf/lukaemon_mmlu_professional_law_1.out
 50%|█████     | 2/4 [00:43<00:43, 21.91s/it]                                              50%|█████     | 2/4 [00:44<00:43, 21.91s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] on GPU 0,1,2,3,4,5,6,7
11/12 02:02:40 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] fail, see
./outputs/default/20231112_020133/logs/infer/llama-7b-hf/lukaemon_mmlu_moral_scenarios.out
 75%|███████▌  | 3/4 [01:07<00:22, 22.55s/it]                                              75%|███████▌  | 3/4 [01:08<00:22, 22.55s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] on GPU 0,1,2,3,4,5,6,7
11/12 02:03:04 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] fail, see
./outputs/default/20231112_020133/logs/infer/llama-7b-hf/lukaemon_mmlu_high_school_physics.out
100%|██████████| 4/4 [01:30<00:00, 22.89s/it]100%|██████████| 4/4 [01:30<00:00, 22.63s/it]
11/12 02:03:04 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] failed with code 1
11/12 02:03:04 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] failed with code 1
11/12 02:03:04 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] failed with code 1
11/12 02:03:04 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] failed with code 1
11/12 02:03:04 - OpenCompass - INFO - Partitioned into 57 tasks.
  0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:01<?, ?it/s]                                        0%|          | 0/57 [00:01<?, ?it/s]                                        0%|          | 0/57 [00:01<?, ?it/s]                                        0%|          | 0/57 [00:01<?, ?it/s]                                        0%|          | 0/57 [00:02<?, ?it/s]                                        0%|          | 0/57 [00:02<?, ?it/s]                                        0%|          | 0/57 [00:03<?, ?it/s]                                        0%|          | 0/57 [00:03<?, ?it/s]                                        0%|          | 0/57 [00:03<?, ?it/s]                                        0%|          | 0/57 [00:04<?, ?it/s]                                        0%|          | 0/57 [00:05<?, ?it/s]                                        0%|          | 0/57 [00:06<?, ?it/s]                                        0%|          | 0/57 [00:06<?, ?it/s]                                        0%|          | 0/57 [00:07<?, ?it/s]                                        0%|          | 0/57 [00:07<?, ?it/s]                                        0%|          | 0/57 [00:08<?, ?it/s]                                        0%|          | 0/57 [00:09<?, ?it/s]                                        0%|          | 0/57 [00:09<?, ?it/s]                                        0%|          | 0/57 [00:11<?, ?it/s]                                        0%|          | 0/57 [00:11<?, ?it/s]                                        0%|          | 0/57 [00:12<?, ?it/s]                                        0%|          | 0/57 [00:13<?, ?it/s]                                        0%|          | 0/57 [00:14<?, ?it/s]                                        0%|          | 0/57 [00:15<?, ?it/s]                                        0%|          | 0/57 [00:16<?, ?it/s]                                        0%|          | 0/57 [00:17<?, ?it/s]  2%|▏         | 1/57 [00:24<23:18, 24.98s/it]                                                2%|▏         | 1/57 [00:25<23:18, 24.98s/it]  4%|▎         | 2/57 [00:25<09:43, 10.62s/it]                                                5%|▌         | 3/57 [00:26<05:27,  6.06s/it]  7%|▋         | 4/57 [00:26<02:32,  2.87s/it]  9%|▉         | 5/57 [00:27<01:57,  2.26s/it]                                               11%|█         | 6/57 [00:27<01:13,  1.45s/it] 11%|█         | 6/57 [00:27<01:13,  1.45s/it] 11%|█         | 6/57 [00:27<01:13,  1.45s/it]                                               14%|█▍        | 8/57 [00:28<01:01,  1.25s/it]                                               16%|█▌        | 9/57 [00:30<01:06,  1.39s/it] 18%|█▊        | 10/57 [00:30<00:57,  1.23s/it]                                                18%|█▊        | 10/57 [00:31<00:57,  1.23s/it] 18%|█▊        | 10/57 [00:31<00:57,  1.23s/it] 18%|█▊        | 10/57 [00:32<00:57,  1.23s/it] 18%|█▊        | 10/57 [00:32<00:57,  1.23s/it]                                                18%|█▊        | 10/57 [00:33<00:57,  1.23s/it]                                                19%|█▉        | 11/57 [00:34<01:17,  1.67s/it]                                                19%|█▉        | 11/57 [00:35<01:17,  1.67s/it]                                                19%|█▉        | 11/57 [00:37<01:17,  1.67s/it] 19%|█▉        | 11/57 [00:37<01:17,  1.67s/it]                                                19%|█▉        | 11/57 [00:37<01:17,  1.67s/it] 23%|██▎       | 13/57 [00:38<01:31,  2.08s/it] 23%|██▎       | 13/57 [00:38<01:31,  2.08s/it]                                                23%|██▎       | 13/57 [00:40<01:31,  2.08s/it]                                                23%|██▎       | 13/57 [00:40<01:31,  2.08s/it] 25%|██▍       | 14/57 [00:42<01:53,  2.64s/it]                                                26%|██▋       | 15/57 [00:43<01:30,  2.15s/it] 26%|██▋       | 15/57 [00:43<01:30,  2.15s/it]                                                28%|██▊       | 16/57 [00:44<01:13,  1.80s/it] 30%|██▉       | 17/57 [00:44<00:53,  1.33s/it] 30%|██▉       | 17/57 [00:44<00:53,  1.33s/it]                                                30%|██▉       | 17/57 [00:45<00:53,  1.33s/it]                                                30%|██▉       | 17/57 [00:45<00:53,  1.33s/it] 32%|███▏      | 18/57 [00:48<01:18,  2.00s/it]                                                35%|███▌      | 20/57 [00:49<00:38,  1.05s/it] 35%|███▌      | 20/57 [00:49<00:38,  1.05s/it] 35%|███▌      | 20/57 [00:50<00:38,  1.05s/it]                                                37%|███▋      | 21/57 [00:50<00:37,  1.05s/it] 37%|███▋      | 21/57 [00:51<00:37,  1.05s/it]                                                39%|███▊      | 22/57 [00:51<00:36,  1.04s/it]                                                39%|███▊      | 22/57 [00:52<00:36,  1.04s/it] 39%|███▊      | 22/57 [00:53<00:36,  1.04s/it]                                                40%|████      | 23/57 [00:54<00:49,  1.44s/it] 42%|████▏     | 24/57 [00:55<00:50,  1.54s/it] 44%|████▍     | 25/57 [00:55<00:48,  1.52s/it]                                                44%|████▍     | 25/57 [00:56<00:48,  1.52s/it] 44%|████▍     | 25/57 [00:56<00:48,  1.52s/it]                                                44%|████▍     | 25/57 [00:57<00:48,  1.52s/it]                                                44%|████▍     | 25/57 [00:59<00:48,  1.52s/it] 46%|████▌     | 26/57 [01:00<01:11,  2.31s/it] 47%|████▋     | 27/57 [01:01<00:59,  1.97s/it] 49%|████▉     | 28/57 [01:01<00:45,  1.56s/it] 51%|█████     | 29/57 [01:05<01:04,  2.29s/it] 53%|█████▎    | 30/57 [01:07<00:56,  2.10s/it] 56%|█████▌    | 32/57 [01:08<00:30,  1.24s/it] 56%|█████▌    | 32/57 [01:08<00:30,  1.24s/it] 58%|█████▊    | 33/57 [01:12<00:55,  2.31s/it] 60%|█████▉    | 34/57 [01:13<00:39,  1.73s/it] 61%|██████▏   | 35/57 [01:13<00:28,  1.30s/it] 63%|██████▎   | 36/57 [01:14<00:23,  1.14s/it] 65%|██████▍   | 37/57 [01:16<00:28,  1.42s/it] 67%|██████▋   | 38/57 [01:18<00:29,  1.58s/it] 68%|██████▊   | 39/57 [01:18<00:21,  1.21s/it] 70%|███████   | 40/57 [01:19<00:20,  1.20s/it] 72%|███████▏  | 41/57 [01:21<00:22,  1.40s/it] 74%|███████▎  | 42/57 [01:21<00:16,  1.13s/it] 75%|███████▌  | 43/57 [01:22<00:13,  1.06it/s] 77%|███████▋  | 44/57 [01:23<00:11,  1.16it/s] 79%|███████▉  | 45/57 [01:23<00:07,  1.53it/s] 81%|████████  | 46/57 [01:23<00:05,  1.93it/s] 82%|████████▏ | 47/57 [01:24<00:05,  1.95it/s] 84%|████████▍ | 48/57 [01:24<00:05,  1.53it/s] 89%|████████▉ | 51/57 [01:25<00:02,  2.63it/s] 91%|█████████ | 52/57 [01:26<00:02,  2.25it/s] 93%|█████████▎| 53/57 [01:26<00:01,  2.73it/s] 95%|█████████▍| 54/57 [01:26<00:01,  2.35it/s] 96%|█████████▋| 55/57 [01:27<00:00,  2.32it/s]100%|██████████| 57/57 [01:27<00:00,  3.69it/s]100%|██████████| 57/57 [01:27<00:00,  1.53s/it]
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_biology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_physics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_electrical_engineering] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_astronomy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_anatomy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_abstract_algebra] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_machine_learning] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_clinical_knowledge] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_global_facts] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_management] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_nutrition] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_marketing] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_accounting] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_geography] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_international_law] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_moral_scenarios] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_computer_security] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_microeconomics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_law] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_medical_genetics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_jurisprudence] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_world_religions] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_philosophy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_virology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_public_relations] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_human_sexuality] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_elementary_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_physics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_european_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_business_ethics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_moral_disputes] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_statistics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_miscellaneous] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_formal_logic] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_prehistory] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_security_studies] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_biology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_logical_fallacies] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_world_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_us_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_sociology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_econometrics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_human_aging] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_us_foreign_policy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_conceptual_physics] on CPU 
dataset                       version    metric    mode    llama-7b-hf
----------------------------  ---------  --------  ------  -------------
------- MMLU details -------  -          -         -       -
mmlu-humanities               -          -         -       -
mmlu-stem                     -          -         -       -
mmlu-social-science           -          -         -       -
mmlu-other                    -          -         -       -
mmlu                          -          -         -       -
11/12 02:04:31 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_020133/summary/summary_20231112_020133.txt
11/12 02:04:31 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_020133/summary/summary_20231112_020133.csv
